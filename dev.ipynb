{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineering Monosemanticity\n",
    "\n",
    "Notes:\n",
    "- Poorly factored code: I'd like to see it reorganized into modules, it should use a config file, optimizer and LR scheduler should be more obvious\n",
    "- Would be cool to have this running on weights and biases. \n",
    "- I want to refactor run into a main and run to seperate repsonsibilities\n",
    "- Tests!!!\n",
    "- defaults on parameters\n",
    "- do casting to tensors inside the argparse wrapper not inside train\n",
    "- write nicer argparse interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t \n",
    "from adam_jermyn.model3 import sample_vectors_equal, sample_vectors_power_law, make_random_embedder\n",
    "\n",
    "N = t.tensor(5); eps = t.tensor(0.1); batch_size = t.tensor(8); m = t.tensor(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder = make_random_embedder(N,m)\n",
    "embedder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, x = sample_vectors_equal(N = N, eps=eps, batch_size = batch_size, embedder=embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace their run file: \n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ToyModelConfig:\n",
    "    '''Constants used throughout your decoder-only transformer model.'''\n",
    "\n",
    "    N: int # number of true features\n",
    "    m: int # embedding dimension (\"bottleneck\")\n",
    "    k: int # width of model\n",
    "    batch_size: int # number of samples in a batch\n",
    "    learning_rate: float # learning rate for optimizer,\n",
    "    eps: float # 1-sparsity of vectors\n",
    "    fixed_embedder: callable #make_random_embedder(N,m),\n",
    "    sampler: callable # sample_vectors_equal,\n",
    "    task: callable # the corresponding samplers from autoencoder, random proj, abs\n",
    "    decay: float # decay rate for bias parameter\n",
    "    reg: float # regularization parameter\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('arena')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b7e6b471291409f54dffbfbdfeccd6f1f2b5fb302e7acf62f723cf276419720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
